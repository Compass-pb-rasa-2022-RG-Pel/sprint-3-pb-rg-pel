{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\juan\\anaconda3\\lib\\site-packages (4.1.1)\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pymongo\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as keras\n",
    "\n",
    " # MongoDB\n",
    "from pymongo import MongoClient\n",
    "import gridfs\n",
    "import io\n",
    "from bson.binary import Binary\n",
    "from bson import ObjectId\n",
    "\n",
    "# exibe as imagens utilizadas como input para treinamento do modelo \n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando imagens de treino a partir da dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normaliza os valores dos pixels para valores entre 0 e 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reserva 6,000 imagens para a validação durante o treinamento\n",
    "val_images = train_images[-6000:]\n",
    "val_labels = train_labels[-6000:]\n",
    "\n",
    "train_images = train_images[:-6000]\n",
    "train_labels = train_labels[:-6000]\n",
    "\n",
    "# A Dataset possui 10 classes definidas\n",
    "# A ordem das classes importa\n",
    "class_names = ['avião', 'automóvel', 'passaro', 'gato','cervo','cachorro', 'sapo', 'cavalo', 'navio', 'caminhao']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(18):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o modelo de rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "historia = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráfico de aprendizado do modelo de rede criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historia.history['accuracy'], label = ['accuracy = projeção esperada'])\n",
    "plt.plot(historia.history['val_accuracy'], label = ['val_accuracy = projeção real'])\n",
    "plt.title('Projeção Real x Projeção Esperada')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precisão')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylim([0.5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo criado com imagens externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(image_path, model_to_training):\n",
    "    test_images = tf.keras.preprocessing.image.load_img(image_path, target_size = (32, 32))\n",
    "    test_images = tf.keras.preprocessing.image.img_to_array(test_images)\n",
    "    test_images = np.expand_dims(test_images, axis = 0)\n",
    "    result = model_to_training.predict(test_images)\n",
    "\n",
    "    print('Essa imagem é:', class_names[result.argmax()])\n",
    "    display(Image(filename=image_path))\n",
    "\n",
    "training('./dataset/aviao.jpg', model)\n",
    "training('./dataset/cachorro2.jpg', model)\n",
    "training('./dataset/caminhao.jpeg', model)\n",
    "training('./dataset/carro.jpg', model)\n",
    "training('./dataset/cavalo.jpg', model)\n",
    "training('./dataset/gato2.jpg', model)\n",
    "training('./dataset/navio.jpg', model)\n",
    "training('./dataset/passaro-cantando.jpg', model)\n",
    "training('./dataset/sapo.jpg', model)\n",
    "training('./dataset/cervo2.jpg', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexão com MongoDB do Okteto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando modelo de rede em arquivo .h5\n",
    "model.save('modelo.h5')  \n",
    "\n",
    "#Conectando com o mongo\n",
    "client = MongoClient(\"mongodb://root:root@mongodb:27017/\")\n",
    "\n",
    "database = client[\"sprint3\"]\n",
    "\n",
    "collection = database[\"modelo\"]\n",
    "\n",
    "#Inserindo modelo de rede treinado no arquivo criado\n",
    "model_file = 'modelo.h5';\n",
    "with open(model_file, \"rb\") as f:\n",
    "    # Convertendo o conteúdo em binário para salvar no banco\n",
    "    encoded = Binary(f.read()) \n",
    "x = collection.insert_one({\"filename\": model_file, \"file\": encoded, \"description\": \"Keras model\" })\n",
    "# Retorna o id do arquivo salvo no banco\n",
    "print(x.inserted_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de imagens a partir do modelo salvo no MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo o modelo salvo no arquivo\n",
    "data = collection.find_one({'filename': 'modelo.h5'})\n",
    "with open(\"keras_model_fromMongo.h5\", \"wb\") as f:\n",
    "    f.write(data['file'])\n",
    "\n",
    "#Lendo imagens a partir do modelo salvo no banco\n",
    "modelo_carregado = keras.models.load_model('keras_model_fromMongo.h5')\n",
    "training('./dataset/aviao.jpg', modelo_carregado)\n",
    "training('./dataset/cachorro2.jpg', modelo_carregado)\n",
    "training('./dataset/caminhao.jpeg', modelo_carregado)\n",
    "training('./dataset/carro.jpg', modelo_carregado)\n",
    "training('./dataset/cavalo.jpg', modelo_carregado)\n",
    "training('./dataset/gato2.jpg', modelo_carregado)\n",
    "training('./dataset/navio.jpg', modelo_carregado)\n",
    "training('./dataset/passaro-cantando.jpg', modelo_carregado)\n",
    "training('./dataset/sapo.jpg', modelo_carregado)\n",
    "training('./dataset/cervo2.jpg', modelo_carregado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
